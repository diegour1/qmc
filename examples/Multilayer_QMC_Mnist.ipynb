{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python388jvsc74a57bd06f5c4f860b8b5392c9fe536844a7572c0d9b36e44085495c747ab5a91e5f3cc1",
      "display_name": "Python 3.8.8 64-bit ('tf_x86': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "6f5c4f860b8b5392c9fe536844a7572c0d9b36e44085495c747ab5a91e5f3cc1"
      }
    },
    "colab": {
      "name": "GPU-QM-DM-mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fagonzalezo/qmc/blob/master/examples/Multilayer_QMC_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLf3P_V29LhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3395e4f0-171d-4616-ed3a-7804162229c9"
      },
      "source": [
        "# Install qmc if running in Google Colab\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install --upgrade  git+https://github.com/fagonzalezo/qmc.git\n",
        "else:\n",
        "    import sys\n",
        "    sys.path.insert(0, \"../\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmwZ_WBj9lq_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import qmc.tf.layers as layers\n",
        "import qmc.tf.models as models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyLwyfpqxN7M",
        "outputId": "8178e742-560b-41da-fbf2-dda968d76172"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape((60000,784))\n",
        "X_test = X_test.reshape((10000,784))\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "transformer = OneHotEncoder(sparse=False)\n",
        "y_train_bin = transformer.fit_transform(y_train[:, np.newaxis])\n",
        "\n",
        "print(\"shape X_train : \", X_train.shape)\n",
        "print(\"shape y_train : \", y_train.shape)\n",
        "print(\"shape X_test : \", X_test.shape)\n",
        "print(\"shape y_test : \", y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape X_train :  (60000, 784)\nshape y_train :  (60000,)\nshape X_test :  (10000, 784)\nshape y_test :  (10000,)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## Baseline"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsNNXRvi92TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a67bbc-2f1c-4857-92c8-78f1c3fc11f5"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "tf.keras.layers.Dense(128,activation='relu'),\n",
        "tf.keras.layers.Dense(10),\n",
        "tf.keras.layers.Softmax()\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
        ")\n",
        "EPOCHS = 10\n",
        "  \n",
        "history = model.fit(X_train, y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\"), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\"), but it was called on an input with incompatible shape (None, 784).\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.8621 - categorical_accuracy: 0.7548WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\"), but it was called on an input with incompatible shape (None, 784).\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.8602 - categorical_accuracy: 0.7553 - val_loss: 0.2469 - val_categorical_accuracy: 0.9327\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.2469 - categorical_accuracy: 0.9304 - val_loss: 0.1915 - val_categorical_accuracy: 0.9467\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.1745 - categorical_accuracy: 0.9499 - val_loss: 0.1550 - val_categorical_accuracy: 0.9560\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.1379 - categorical_accuracy: 0.9612 - val_loss: 0.1333 - val_categorical_accuracy: 0.9620\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.1118 - categorical_accuracy: 0.9698 - val_loss: 0.1217 - val_categorical_accuracy: 0.9644\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0973 - categorical_accuracy: 0.9733 - val_loss: 0.1138 - val_categorical_accuracy: 0.9660\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0826 - categorical_accuracy: 0.9776 - val_loss: 0.1091 - val_categorical_accuracy: 0.9668\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0747 - categorical_accuracy: 0.9795 - val_loss: 0.1036 - val_categorical_accuracy: 0.9698\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0658 - categorical_accuracy: 0.9818 - val_loss: 0.0986 - val_categorical_accuracy: 0.9708\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0586 - categorical_accuracy: 0.9842 - val_loss: 0.0946 - val_categorical_accuracy: 0.9714\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## Full training"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWmn69C0JKL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d82d510-4c0a-4515-f95a-e712fff80a62"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "input_dim = 784\n",
        "num_rff = 512\n",
        "gamma = 2**-5\n",
        "n_comp = 80\n",
        "random_state = 0\n",
        "dim_h = 30\n",
        "\n",
        "inputs = tf.keras.Input(shape=(784,))\n",
        "fm_x1 = layers.QFeatureMapRFF(784, dim=num_rff , gamma=gamma, random_state=random_state)\n",
        "psi_x = fm_x1(inputs)\n",
        "ones = tf.ones_like(inputs[:, 0:1])\n",
        "rho_x = tf.keras.layers.concatenate((ones, psi_x), axis=1)\n",
        "rho_x = tf.expand_dims(rho_x, axis=-1)\n",
        "qmdmc1 = layers.QMClassifSDecompFDMatrix(dim_x=num_rff, dim_y=dim_h, n_comp=n_comp)\n",
        "rho_h = qmdmc1(rho_x)\n",
        "qmdmc2 = layers.QMClassifSDecompFDMatrix(dim_x=dim_h, dim_y=10, n_comp=n_comp)\n",
        "rho_y = qmdmc2(rho_h)\n",
        "y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v))\n",
        "qmdmclf2 = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "qmdmclf2.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# fm_x1.trainable = False\n",
        "\n",
        "EPOCHS = 10\n",
        "  \n",
        "history = qmdmclf2.fit(X_train, y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 14s 71ms/step - loss: 1.4059 - accuracy: 0.6052 - val_loss: 0.4334 - val_accuracy: 0.8520\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.3891 - accuracy: 0.8684 - val_loss: 0.3760 - val_accuracy: 0.8718\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.3196 - accuracy: 0.8852 - val_loss: 0.3456 - val_accuracy: 0.8658\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2874 - accuracy: 0.8900 - val_loss: 0.3297 - val_accuracy: 0.8795\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.2688 - accuracy: 0.8929 - val_loss: 0.3179 - val_accuracy: 0.8816\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2562 - accuracy: 0.8962 - val_loss: 0.3091 - val_accuracy: 0.8827\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2380 - accuracy: 0.9016 - val_loss: 0.3041 - val_accuracy: 0.8826\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.2315 - accuracy: 0.9001 - val_loss: 0.2990 - val_accuracy: 0.8840\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.2213 - accuracy: 0.9027 - val_loss: 0.2964 - val_accuracy: 0.8843\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.2165 - accuracy: 0.9028 - val_loss: 0.2922 - val_accuracy: 0.8843\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## Layerwise training"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOte8WRc999W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e2a6cd-a94c-43bd-daf8-a12849f616d6"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "input_dim = 784\n",
        "component_dim = 128\n",
        "gamma = 2**-5\n",
        "n_comp = 80\n",
        "random_state = 0\n",
        "\n",
        "inputs = tf.keras.Input(shape=(784,))\n",
        "fm_x = layers.QFeatureMapRFF(784, dim=component_dim , gamma=gamma, random_state=random_state)\n",
        "psi_x = fm_x(inputs)\n",
        "ones = tf.ones_like(inputs[:, 0:1])\n",
        "rho_x = tf.keras.layers.concatenate((ones, psi_x), axis=1)\n",
        "rho_x = tf.expand_dims(rho_x, axis=-1)\n",
        "#qmdmc = layers.QMeasureDMClassifEig(dim_x=component_dim , dim_y=10, eig_out=num_eig, num_eig=num_eig)\n",
        "qmdmc = layers.QMClassifSDecompFDMatrix(dim_x=component_dim, dim_y=10, n_comp=n_comp)\n",
        "rho_y = qmdmc(rho_x)\n",
        "y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v))\n",
        "qmdmclf = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "qmdmclf.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 10\n",
        "  \n",
        "history = qmdmclf.fit(X_train, y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 1.6390 - accuracy: 0.4964 - val_loss: 0.5697 - val_accuracy: 0.8938\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 0.5328 - accuracy: 0.8988 - val_loss: 0.4274 - val_accuracy: 0.9255\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 0.3972 - accuracy: 0.9301 - val_loss: 0.3680 - val_accuracy: 0.9365\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 8s 41ms/step - loss: 0.3344 - accuracy: 0.9439 - val_loss: 0.3350 - val_accuracy: 0.9425\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 0.2952 - accuracy: 0.9519 - val_loss: 0.3137 - val_accuracy: 0.9472\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 0.2704 - accuracy: 0.9568 - val_loss: 0.2934 - val_accuracy: 0.9497\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 0.2484 - accuracy: 0.9624 - val_loss: 0.2777 - val_accuracy: 0.9523\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 0.2335 - accuracy: 0.9644 - val_loss: 0.2648 - val_accuracy: 0.9553\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 0.2208 - accuracy: 0.9670 - val_loss: 0.2553 - val_accuracy: 0.9565\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 8s 42ms/step - loss: 0.2115 - accuracy: 0.9691 - val_loss: 0.2505 - val_accuracy: 0.9576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrZ2k0KLHxus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04074a5e-daed-405a-b18c-dec6652fe284"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(784,))\n",
        "fm_x1 = layers.QFeatureMapRFF(784, dim=component_dim , gamma=gamma, random_state=random_state)\n",
        "psi_x = fm_x1(inputs)\n",
        "ones = tf.ones_like(inputs[:, 0:1])\n",
        "rho_x = tf.keras.layers.concatenate((ones, psi_x), axis=1)\n",
        "rho_x = tf.expand_dims(rho_x, axis=-1)\n",
        "qmdmc1 = layers.QMClassifSDecompFDMatrix(dim_x=component_dim, dim_y=10, n_comp=n_comp)\n",
        "rho_h = qmdmc1(rho_x)\n",
        "qmdmc2 = layers.QMClassifSDecompFDMatrix(dim_x=10, dim_y=10, n_comp=n_comp)\n",
        "rho_y = qmdmc2(rho_h)\n",
        "y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v))\n",
        "qmdmclf2 = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "qmdmclf2.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# We freeze the weights of the first layer and train the second\n",
        "fm_x1.set_weights(fm_x.get_weights())\n",
        "fm_x1.trainable = False\n",
        "qmdmc1.set_weights(qmdmc.get_weights())\n",
        "qmdmc1.trainable = False\n",
        "EPOCHS = 5\n",
        "  \n",
        "history = qmdmclf2.fit(X_train, y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "188/188 [==============================] - 11s 53ms/step - loss: 1.0492 - accuracy: 0.9238 - val_loss: 0.2500 - val_accuracy: 0.9600\n",
            "Epoch 2/5\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.1993 - accuracy: 0.9727 - val_loss: 0.2382 - val_accuracy: 0.9615\n",
            "Epoch 3/5\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.1867 - accuracy: 0.9752 - val_loss: 0.2278 - val_accuracy: 0.9626\n",
            "Epoch 4/5\n",
            "188/188 [==============================] - 11s 56ms/step - loss: 0.1770 - accuracy: 0.9775 - val_loss: 0.2237 - val_accuracy: 0.9640\n",
            "Epoch 5/5\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1703 - accuracy: 0.9783 - val_loss: 0.2213 - val_accuracy: 0.9646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 10s 53ms/step - loss: 0.1661 - accuracy: 0.9786 - val_loss: 0.2182 - val_accuracy: 0.9656\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1606 - accuracy: 0.9796 - val_loss: 0.2116 - val_accuracy: 0.9663\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1562 - accuracy: 0.9804 - val_loss: 0.2100 - val_accuracy: 0.9660\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1512 - accuracy: 0.9812 - val_loss: 0.2074 - val_accuracy: 0.9654\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1472 - accuracy: 0.9820 - val_loss: 0.2066 - val_accuracy: 0.9663\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1433 - accuracy: 0.9826 - val_loss: 0.2030 - val_accuracy: 0.9676\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1399 - accuracy: 0.9835 - val_loss: 0.2011 - val_accuracy: 0.9675\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1365 - accuracy: 0.9839 - val_loss: 0.1991 - val_accuracy: 0.9674\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1336 - accuracy: 0.9848 - val_loss: 0.1957 - val_accuracy: 0.9670\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 10s 52ms/step - loss: 0.1306 - accuracy: 0.9852 - val_loss: 0.1954 - val_accuracy: 0.9677\n"
          ]
        }
      ],
      "source": [
        "# We free all the weights and fine tune\n",
        "\n",
        "fm_x1.trainable = True\n",
        "qmdmc1.trainable = True\n",
        "EPOCHS = 10\n",
        "history = qmdmclf2.fit(X_train, y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diEm3hzi31v1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}