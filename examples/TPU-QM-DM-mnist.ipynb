{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python388jvsc74a57bd06f5c4f860b8b5392c9fe536844a7572c0d9b36e44085495c747ab5a91e5f3cc1",
      "display_name": "Python 3.8.8 64-bit ('tf_x86': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "6f5c4f860b8b5392c9fe536844a7572c0d9b36e44085495c747ab5a91e5f3cc1"
      }
    },
    "colab": {
      "name": "TPU-QM-DM-mnist.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SovY65Wo9LhM"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fagonzalezo/qmc/blob/master/examples/TPU-QM-DM-mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLf3P_V29LhR",
        "outputId": "89e936ac-bf7e-4880-81f1-55be6cc96a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install qmc if running in Google Colab\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install git+https://github.com/fagonzalezo/qmc.git\n",
        "else:\n",
        "    import sys\n",
        "    sys.path.insert(0, \"../\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/fagonzalezo/qmc.git\n",
            "  Cloning https://github.com/fagonzalezo/qmc.git to /tmp/pip-req-build-982t6st3\n",
            "  Running command git clone -q https://github.com/fagonzalezo/qmc.git /tmp/pip-req-build-982t6st3\n",
            "Requirement already satisfied (use --upgrade to upgrade): qmc==0.0.1 from git+https://github.com/fagonzalezo/qmc.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (2.4.1)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (2.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->qmc==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (3.12.4)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (0.36.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (56.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.3.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.4.1)\n",
            "Building wheels for collected packages: qmc\n",
            "  Building wheel for qmc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qmc: filename=qmc-0.0.1-cp37-none-any.whl size=11694 sha256=8a185179a4c05e7434b83e44d8e8cef0b4ccd24cd90871ba037e116c15a86da2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pgtsgvms/wheels/ff/c2/53/58cb50bb85949fb1dcda723a7c1f48a590515dee0aa40a4cc2\n",
            "Successfully built qmc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmwZ_WBj9lq_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import qmc.tf.layers as layers\n",
        "import qmc.tf.models as models"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO7oEcqA-qNP",
        "outputId": "29a20151-37fa-4d4b-9ba1-82d7f0d96a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.4.189.194:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.4.189.194:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.4.189.194:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyfGmmgd9dyL"
      },
      "source": [
        "BATCH_SIZE = 64 * tpu_strategy.num_replicas_in_sync\n",
        "training_images_file   = 'gs://mnist-public/train-images-idx3-ubyte'\n",
        "training_labels_file   = 'gs://mnist-public/train-labels-idx1-ubyte'\n",
        "validation_images_file = 'gs://mnist-public/t10k-images-idx3-ubyte'\n",
        "validation_labels_file = 'gs://mnist-public/t10k-labels-idx1-ubyte'\n",
        "def read_label(tf_bytestring):\n",
        "    label = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "  \n",
        "def read_image(tf_bytestring):\n",
        "    image = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/256.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "  \n",
        "def load_dataset(image_file, label_file):\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
        "    return dataset \n",
        "  \n",
        "def get_training_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache()  # this small dataset can be entirely cached in RAM\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(-1)  # fetch next batches while training on the current one (-1: autotune prefetch buffer size)\n",
        "    return dataset\n",
        "  \n",
        "def get_validation_dataset(image_file, label_file):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache() # this small dataset can be entirely cached in RAM\n",
        "    dataset = dataset.batch(10000)\n",
        "    return dataset\n",
        "\n",
        "# instantiate the datasets\n",
        "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsNNXRvi92TV",
        "outputId": "f933569b-52e0-49fc-94c5-389d7b21c676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Softmax()\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
        "    )\n",
        "EPOCHS = 10\n",
        "steps_per_epoch = 60000//BATCH_SIZE  # 60,000 items in this dataset\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\n",
        "  \n",
        "history = model.fit(training_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                    validation_data=validation_dataset, validation_steps=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  117\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_4_input'), name='flatten_4_input', description=\"created by layer 'flatten_4_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_4_input'), name='flatten_4_input', description=\"created by layer 'flatten_4_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_4_input'), name='flatten_4_input', description=\"created by layer 'flatten_4_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_4_input'), name='flatten_4_input', description=\"created by layer 'flatten_4_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "115/117 [============================>.] - ETA: 0s - loss: 1.9078 - categorical_accuracy: 0.6519WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_4_input'), name='flatten_4_input', description=\"created by layer 'flatten_4_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_4_input'), name='flatten_4_input', description=\"created by layer 'flatten_4_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "117/117 [==============================] - 6s 30ms/step - loss: 1.9031 - categorical_accuracy: 0.6559 - val_loss: 1.5721 - val_categorical_accuracy: 0.9108\n",
            "Epoch 2/10\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 1.5672 - categorical_accuracy: 0.9159 - val_loss: 1.5477 - val_categorical_accuracy: 0.9276\n",
            "Epoch 3/10\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 1.5462 - categorical_accuracy: 0.9284 - val_loss: 1.5360 - val_categorical_accuracy: 0.9350\n",
            "Epoch 4/10\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 1.5332 - categorical_accuracy: 0.9391 - val_loss: 1.5285 - val_categorical_accuracy: 0.9409\n",
            "Epoch 5/10\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 1.5248 - categorical_accuracy: 0.9453 - val_loss: 1.5228 - val_categorical_accuracy: 0.9452\n",
            "Epoch 6/10\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 1.5191 - categorical_accuracy: 0.9503 - val_loss: 1.5186 - val_categorical_accuracy: 0.9480\n",
            "Epoch 7/10\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 1.5137 - categorical_accuracy: 0.9547 - val_loss: 1.5153 - val_categorical_accuracy: 0.9509\n",
            "Epoch 8/10\n",
            "117/117 [==============================] - 2s 18ms/step - loss: 1.5093 - categorical_accuracy: 0.9584 - val_loss: 1.5116 - val_categorical_accuracy: 0.9539\n",
            "Epoch 9/10\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 1.5047 - categorical_accuracy: 0.9630 - val_loss: 1.5091 - val_categorical_accuracy: 0.9567\n",
            "Epoch 10/10\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 1.5021 - categorical_accuracy: 0.9651 - val_loss: 1.5085 - val_categorical_accuracy: 0.9573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOte8WRc999W",
        "outputId": "4070ce15-7b1d-41d4-fd31-659ed22979ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_dim = 784\n",
        "component_dim = 128\n",
        "gamma = 2**-5\n",
        "num_eig = 80\n",
        "random_state = 0\n",
        "LEARNING_RATE = 0.001\n",
        "LEARNING_RATE_EXP_DECAY = 0.6 if tpu_strategy.num_replicas_in_sync == 1 else 0.7\n",
        "lr_decay = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch,\n",
        "    verbose=True)\n",
        "\n",
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "    inputs = tf.keras.Input(shape=(784,))\n",
        "    fm_x = layers.QFeatureMapRFF(784, dim=component_dim , gamma=gamma, random_state=random_state)\n",
        "    psi_x = fm_x(inputs)\n",
        "    ones = tf.ones_like(inputs[:, 0:1])\n",
        "    rho_x = tf.keras.layers.concatenate((ones, psi_x), axis=1)\n",
        "    rho_x = tf.expand_dims(rho_x, axis=-1)\n",
        "    qmdmc = layers.QMeasureDMClassifEig(dim_x=component_dim , dim_y=10, eig_out=num_eig * 2, num_eig=num_eig)\n",
        "    rho_y = qmdmc(rho_x)\n",
        "    y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "    y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "    probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v))\n",
        "    qmdmc = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
        "    qmdmc.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 10\n",
        "steps_per_epoch = 60000//BATCH_SIZE  # 60,000 items in this dataset\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\n",
        "  \n",
        "history = qmdmc.fit(training_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                    validation_data=validation_dataset, validation_steps=1,\n",
        "                    callbacks=[lr_decay])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  117\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
            "117/117 [==============================] - 10s 41ms/step - loss: 2.0566 - accuracy: 0.3191 - val_loss: 1.4221 - val_accuracy: 0.6684\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0007.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 1.3502 - accuracy: 0.6869 - val_loss: 1.1410 - val_accuracy: 0.7287\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00049.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 1.1275 - accuracy: 0.7365 - val_loss: 1.0572 - val_accuracy: 0.7521\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00034299999999999993.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 1.0554 - accuracy: 0.7599 - val_loss: 1.0180 - val_accuracy: 0.7620\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00024009999999999995.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 1.0139 - accuracy: 0.7704 - val_loss: 0.9931 - val_accuracy: 0.7667\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00016806999999999995.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.9882 - accuracy: 0.7757 - val_loss: 0.9718 - val_accuracy: 0.7667\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00011764899999999997.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.9675 - accuracy: 0.7751 - val_loss: 0.9590 - val_accuracy: 0.7734\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 8.235429999999997e-05.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.9565 - accuracy: 0.7772 - val_loss: 0.9513 - val_accuracy: 0.7734\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 5.7648009999999975e-05.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.9488 - accuracy: 0.7802 - val_loss: 0.9469 - val_accuracy: 0.7761\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 4.035360699999998e-05.\n",
            "117/117 [==============================] - 3s 22ms/step - loss: 0.9437 - accuracy: 0.7840 - val_loss: 0.9433 - val_accuracy: 0.7756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrZ2k0KLHxus"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}